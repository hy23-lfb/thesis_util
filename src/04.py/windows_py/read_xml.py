# -*- coding: utf-8 -*-
"""read_xml.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1rkVGIqXVAfVAuF9R0o0PY2qpn62O6KXa
"""

import numpy as np
from tabulate import tabulate
import xml.etree.ElementTree as ET

import os

def read_xml(file):

  path, filename  = os.path.split(file)
  name, ext       = os.path.splitext(filename)
  info_dict = dict()

  tree = ET.parse(file)
  root = tree.getroot()

  for child in root:
    info_dict["name"] = name
    points = list()
    points.append(float(child.attrib['x']))
    points.append(float(child.attrib['y']))
    points.append(float(child.attrib['z']))
    info_dict[child.attrib['name'].lower()] = points

  return info_dict

def read_atlas(file):
  info_atlas = read_xml(file)
  return info_atlas

def save_csv(file, data):
  path, filename  = os.path.split(file)
  name, ext       = os.path.splitext(filename)

  out_file = os.path.join(path, name + "_LRE.csv")

  col_names = ["Landmarks", "x", "y", "z"]
  # https://pypi.org/project/tabulate/
  content2 = tabulate(data, headers=col_names, tablefmt="tsv")
  text_file=open(out_file,"w")
  text_file.write(content2)
  text_file.close()
  return

def landmark_reg_error(error):
  return np.linalg.norm(np.array(error))

def calculate_lre(info_atlas, file):
  info_mov  = read_xml(file)
  
  info_lre  = dict()
  for key in info_atlas:
    if key == 'name':
      info_lre['name'] = info_mov[key]
    else:
      error = list()
      for item1, item2 in zip(info_atlas[key], info_mov[key]):
        error.append(item1-item2)
    
      csv_data = list()
      csv_data.append(list([key, error[0], error[1], error[2]]))

      lre           = landmark_reg_error(error)
      info_lre[key] = lre

  save_csv(file, csv_data)
  return info_lre

def computeLRE_forAll(filepath):
  list_lre_info   = list()
  for filename in os.listdir(filepath):
    if filename.endswith(".points"):
      file  = os.path.join(filepath, filename)
      info_lre  =  calculate_lre(info_atlas, file)
      list_lre_info.append(info_lre)
    
  return list_lre_info

def compute_mean_and_std(landmark_error_of_all_scans):
  mean  = np.mean(np.array(landmark_error_of_all_scans[1:]))
  var   = np.var(np.array(landmark_error_of_all_scans[1:]))
  std   = np.sqrt(var)

  return [mean, std]

def computeLRE_tabular(list_lre_info, info_atlas):
  table = list()
  for key in info_atlas:
    landmark_error_of_all_scans = list()
    if key == 'name':
      continue
    landmark_error_of_all_scans.append(key)
    for i in range(len(list_lre_info)):
      one_lre_info = list_lre_info[i]
      landmark_error_of_all_scans.append(one_lre_info[key])
    
    # compute mean and std.
    mean, std = compute_mean_and_std(landmark_error_of_all_scans)
    
    landmark_error_of_all_scans.append(mean)
    landmark_error_of_all_scans.append(std)
    
    table.append(landmark_error_of_all_scans)
  return table

def save_tabular(filepath, ld_lre):
  save_file = os.path.join(filepath, 'table.csv')

filepath    = '/content'
info_atlas  = read_atlas('/content/atlas/L3-NP-template.points')

# "list_lre_info" is list of dictionaries.
list_lre_info  = computeLRE_forAll(filepath)

# "table" is list of list for 'tabulate'
tabular_data = computeLRE_tabular(list_lre_info, info_atlas)

save_tabular(filepath, list_lre_info)

save_file = os.path.join(filepath, 'table.csv')
col_names = list()
col_names.append("Landmarks")

for i in range(len(list_lre_info)):
  col_names.append(list_lre_info[i]["name"])

col_names.append("mean")
col_names.append("std")

content2 = tabulate(tabular_data, headers=col_names, tablefmt="tsv")
text_file=open(save_file,"w")
text_file.write(content2)
text_file.close()

